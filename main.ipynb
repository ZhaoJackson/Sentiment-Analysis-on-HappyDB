{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db6376e6-55f3-49d7-8227-07832aeae69f",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on HappyDB Dataset\n",
    "\n",
    "## Overview\n",
    "This notebook performs comprehensive sentiment analysis on the HappyDB dataset, focusing on gender-based differences in emotional expression across different age groups.\n",
    "\n",
    "## Research Questions\n",
    "1. How do men and women express happiness differently?\n",
    "2. Do sentiment words change with age?\n",
    "3. What are the most common emotional words in happy moments?\n",
    "4. Are there gender-specific patterns in emotional expression?\n",
    "\n",
    "## Workflow\n",
    "1. **Setup & Imports** - Load required libraries\n",
    "2. **Data Loading & Preprocessing** - Load and clean datasets\n",
    "3. **Text Processing Functions** - Define preprocessing and analysis functions\n",
    "4. **Sentiment Analysis** - Apply VADER sentiment analysis\n",
    "5. **Gender-based Analysis** - Compare male vs female sentiment patterns\n",
    "6. **Visualization** - Generate comparison charts\n",
    "7. **Results & Insights** - Analyze findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acff64a-bc3e-4b3f-9667-2317052b5d3f",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n",
    "\n",
    "Load all required libraries for data analysis, natural language processing, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c23aa5fb-4411-4746-9ca1-a3b3aedb71d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# Natural Language Processing\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76f9b89",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Preprocessing\n",
    "\n",
    "Load the HappyDB dataset and demographic information, then merge and filter the data for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63d467d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading datasets...\n",
      "Demographic data shape: (10844, 6)\n",
      "Happy moments data shape: (100535, 9)\n",
      "Merged data shape: (100535, 14)\n",
      "US participants: 79063\n",
      "Male participants: 44259\n",
      "Female participants: 34100\n",
      "‚úÖ Data loading and preprocessing completed!\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "print(\"üìä Loading datasets...\")\n",
    "demographic_df = pd.read_csv('./data/demographic.csv')\n",
    "cleaned_hm_df = pd.read_csv('./data/cleaned_hm.csv')\n",
    "\n",
    "print(f\"Demographic data shape: {demographic_df.shape}\")\n",
    "print(f\"Happy moments data shape: {cleaned_hm_df.shape}\")\n",
    "\n",
    "# Merge datasets\n",
    "merged_data = pd.merge(cleaned_hm_df, demographic_df, on='wid', how='inner')\n",
    "print(f\"Merged data shape: {merged_data.shape}\")\n",
    "\n",
    "# Filter for US participants only\n",
    "us_data = merged_data[merged_data['country'] == 'USA'].copy()\n",
    "print(f\"US participants: {len(us_data)}\")\n",
    "\n",
    "# Split by gender\n",
    "male_data = us_data[us_data['gender'] == 'm'].copy()\n",
    "female_data = us_data[us_data['gender'] == 'f'].copy()\n",
    "\n",
    "print(f\"Male participants: {len(male_data)}\")\n",
    "print(f\"Female participants: {len(female_data)}\")\n",
    "\n",
    "# Save processed data\n",
    "male_data.to_csv('./output/male_data.csv', index=False)\n",
    "female_data.to_csv('./output/female_data.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Data loading and preprocessing completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f40d08",
   "metadata": {},
   "source": [
    "## 3. Text Processing Functions\n",
    "\n",
    "Define all necessary functions for text preprocessing, sentiment analysis, and data processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de11ef5b-f7d0-41f6-bc5b-3a46e2c2d8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Text preprocessing function defined!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jacksonzhao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/jacksonzhao/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEXT PREPROCESSING FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def simple_preprocess(text):\n",
    "    \"\"\"\n",
    "    Perform simple preprocessing on the given text.\n",
    "    - Convert text to lowercase.\n",
    "    - Remove non-alphabetic characters, keeping only letters and spaces.\n",
    "    - Split text into individual words.\n",
    "    \n",
    "    Parameters:\n",
    "    - text (str): The text to be preprocessed.\n",
    "    \n",
    "    Returns:\n",
    "    - list: A list of preprocessed words from the text.\n",
    "    \"\"\"\n",
    "    text = text.lower()  # Convert text into lowercase\n",
    "    text = ''.join(char for char in text if char.isalpha() or char.isspace())  # Remove non-alphabetic characters\n",
    "    words = text.split()  # Split text into words\n",
    "    return words\n",
    "\n",
    "print(\"‚úÖ Text preprocessing function defined!\")\n",
    "\n",
    "def process_data(data_path, age_column, text_column, gender_prefix): # proces gender-specific data for analysis\n",
    "    \"\"\"\n",
    "     Process gender-specific data including text preprocessing, sentiment analysis, and age normalization.\n",
    "     Parameters:\n",
    "     - data_path (str): Path to the CSV file containing the data.\n",
    "     - age_column (str): Name of the column containing age information.\n",
    "     - text_column (str): Name of the column containing text data to be processed.\n",
    "     - gender_prefix (str): Prefix to distinguish between male and female data.\n",
    "     Returns:\n",
    "     - Tuple of processed results: most_common_filtered_words, sentiment_word_freq_by_valid_age\n",
    "    \"\"\"\n",
    "\n",
    "    # data loading\n",
    "    data_df = pd.read_csv(data_path)\n",
    "    data_df[f'{gender_prefix}_processed_text'] = data_df[text_column].apply(simple_preprocess) # Text Preprocessing by converting text to lowercase, removing non-alphabetic characters, and tokenizing\n",
    "\n",
    "    # Calculate word frequency and identify most common words\n",
    "    all_words = [word for text in data_df[f'{gender_prefix}_processed_text'] for word in text]\n",
    "    english_stopwords = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in all_words if word not in english_stopwords]\n",
    "    filtered_word_freq = Counter(filtered_words)\n",
    "    most_common_filtered_words = filtered_word_freq.most_common(20)\n",
    "\n",
    "    # Instantiate VADER SentimentIntensityAnalyzer: focus on sentiment words to understand emotional tone of text.\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    vader_lexicon = sia.lexicon\n",
    "    sentiment_words_from_filtered = [word for word in filtered_words if word in vader_lexicon]\n",
    "    unique_sentiment_words = list(set(sentiment_words_from_filtered))\n",
    "\n",
    "    # Applying age normalization\n",
    "    data_df[f'normalized_age_{gender_prefix}'] = data_df[age_column].apply(normalize_age)\n",
    "    valid_age_data_df = data_df.dropna(subset=[f'normalized_age_{gender_prefix}'])\n",
    "    grouped_texts = valid_age_data_df.groupby(f'normalized_age_{gender_prefix}')[f'{gender_prefix}_processed_text']\n",
    "    age_grouped_text_valid = grouped_texts.apply(lambda texts: ' '.join(' '.join(text) for text in texts))\n",
    "\n",
    "    # Word frequency analysis with valid age groups\n",
    "    word_freq_by_valid_age = {}\n",
    "\n",
    "    for age, text in age_grouped_text_valid.items():\n",
    "        words = text.split()\n",
    "        filtered_words = [word for word in words if word not in english_stopwords]\n",
    "        word_freq = Counter(filtered_words)\n",
    "        word_freq_by_valid_age[age] = word_freq\n",
    "\n",
    "    # Analyzing sentiment word frequency by age\n",
    "    sentiment_word_freq_by_valid_age = pd.DataFrame({\n",
    "        word: [word_freq_by_valid_age[age][word] for age in word_freq_by_valid_age] for word in unique_sentiment_words\n",
    "    }, index=word_freq_by_valid_age.keys())\n",
    "\n",
    "    return data_df, most_common_filtered_words, sentiment_word_freq_by_valid_age\n",
    "\n",
    "# Ensure stopwords and VADER's lexicon are available\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Age Normalization\n",
    "def normalize_age(age):\n",
    "    \"\"\"\n",
    "    Function to normalize age values.\n",
    "    Returns None for non-numeric or invalid age values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(float(age))\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "# Combine age normalization and basic stopwords\n",
    "def process_data_for_age_with_basic_stopwords_corrected(df, text_column, age_column):\n",
    "    \"\"\"\n",
    "    Process data to calculate word frequencies by age, excluding basic stopwords, and identify top 10 words by percentage.\n",
    "    Correctly handles non-numeric age values by excluding them from the analysis.\n",
    "    \"\"\"\n",
    "    # Apply simple preprocess and normalize age with exclusion of non-numeric values\n",
    "    df['processed_text'] = df[text_column].apply(simple_preprocess)\n",
    "    df['normalized_age'] = df[age_column].apply(lambda x: np.nan if not str(x).isdigit() else int(float(x)))\n",
    "\n",
    "    # Drop rows with NaN ages\n",
    "    valid_data_df = df.dropna(subset=['normalized_age'])\n",
    "\n",
    "    # Aggregate texts by age\n",
    "    aggregated_texts_by_age = valid_data_df.groupby('normalized_age')['processed_text'].agg(sum)\n",
    "\n",
    "    # Calculate word frequencies and percentages\n",
    "    word_freq_percentage_by_age = {}\n",
    "    for age, texts in aggregated_texts_by_age.items():\n",
    "        english_stopwords = set(stopwords.words('english'))\n",
    "        filtered_words = [word for word in texts if word not in english_stopwords]\n",
    "        word_freq = Counter(filtered_words)\n",
    "        total_words = sum(word_freq.values())\n",
    "        word_freq_percentage = {word: (count / total_words) * 100 for word, count in word_freq.items()}\n",
    "        # Sort words by frequency percentage and get top 10\n",
    "        top_10_words = sorted(word_freq_percentage.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        word_freq_percentage_by_age[age] = top_10_words\n",
    "\n",
    "    return word_freq_percentage_by_age\n",
    "\n",
    "# Extract top 10 words for each age\n",
    "def extract_word_values(word_freq_data, target_word):\n",
    "    \"\"\"\n",
    "    Extracts and returns the values associated with the target word for each age group\n",
    "    in the provided data structure.\n",
    "\n",
    "    Parameters:\n",
    "    - word_freq_data: A dictionary with age groups as keys and lists of (word, value) tuples as values.\n",
    "    - target_word: The word for which values are to be extracted across all age groups.\n",
    "\n",
    "    Returns:\n",
    "    - results_df: A pandas DataFrame with two columns: 'Age' and '{target_word} Value', where each row corresponds\n",
    "      to an age group and its value for the target word. If the target word is not present, the value will be None.\n",
    "    \"\"\"\n",
    "    # Initialize an empty dictionary to store the results\n",
    "    results = {}\n",
    "    \n",
    "    # Iterate over each age group in the data\n",
    "    for age, word_values in word_freq_data.items():\n",
    "        # Initialize the value for the target word as None for each age group\n",
    "        value_for_target_word = None\n",
    "        \n",
    "        # Search for the target word entry\n",
    "        for word, value in word_values:\n",
    "            if word == target_word:\n",
    "                value_for_target_word = value\n",
    "                break  # Stop searching once the target word is found\n",
    "        \n",
    "        # Assign the found value or None to the results dictionary\n",
    "        results[age] = value_for_target_word\n",
    "\n",
    "    # Convert the dictionary to a DataFrame and dynamically name the 'Value' column based on the target word\n",
    "    results_df = pd.DataFrame(list(results.items()), columns=['Age', f'{target_word} Value'])\n",
    "\n",
    "    # Return the DataFrame\n",
    "    return results_df\n",
    "\n",
    "def merge_word_values_by_age(word_freq_data, words):\n",
    "    \"\"\"\n",
    "    Merges the values for a list of words across age groups into a single DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - word_freq_data: A dictionary with age groups as keys and lists of (word, value) tuples as values.\n",
    "    - words: A list of words to extract and merge values for.\n",
    "\n",
    "    Returns:\n",
    "    - merged_results_df: A pandas DataFrame with age groups as rows and each word's values as columns.\n",
    "    \"\"\"\n",
    "    # Initialize an empty DataFrame to hold the merged results\n",
    "    merged_results_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate over each word to extract its values and merge the results\n",
    "    for word in words:\n",
    "        # Extract values for the current word\n",
    "        results_df = extract_word_values(word_freq_data, word)\n",
    "        \n",
    "        # Rename the column to reflect the current word's values\n",
    "        results_df.rename(columns={f'{word} Value': f'{word}_value'}, inplace=True)\n",
    "        \n",
    "        # If it's the first word, initialize the merged DataFrame with the age and word's value\n",
    "        if merged_results_df.empty:\n",
    "            merged_results_df = results_df\n",
    "        else:\n",
    "            # For subsequent words, merge on 'Age' to ensure alignment across age groups\n",
    "            merged_results_df = pd.merge(merged_results_df, results_df, on='Age', how='outer')\n",
    "\n",
    "    # Return the final merged DataFrame\n",
    "    return merged_results_df\n",
    "\n",
    "\n",
    "# visualize the frequency of a specific word across different ages for male and female participants\n",
    "def plot_word_frequency(word, merged_df, output_directory = '../output/word_frequency_compare/'):\n",
    "\n",
    "    # Check if the word columns exist in the DataFrame, and if not, initialize them to 0\n",
    "    if f'{word}_male' not in merged_df.columns:\n",
    "        merged_df[f'{word}_male'] = 0\n",
    "    if f'{word}_female' not in merged_df.columns:\n",
    "        merged_df[f'{word}_female'] = 0\n",
    "        \n",
    "    # Filling NaN values with 0 for plotting purposes\n",
    "    plot_data = merged_df[['Age', f'{word}_male', f'{word}_female']].fillna(0)\n",
    "    \n",
    "    # Setting the figure size for better visibility, making it wider\n",
    "    plt.figure(figsize=(14, 6))  # Increased width for a wider chart\n",
    "    \n",
    "    # Creating the bar chart\n",
    "    # Setting the position of bars on the X-axis\n",
    "    bar_width = 0.35\n",
    "    r1 = range(len(plot_data))\n",
    "    r2 = [x + bar_width for x in r1]\n",
    "    \n",
    "    # Making the plot\n",
    "    plt.bar(r1, plot_data[f'{word}_male'], color='b', width=bar_width, edgecolor='grey', label='Male')\n",
    "    plt.bar(r2, plot_data[f'{word}_female'], color='r', width=bar_width, edgecolor='grey', label='Female')\n",
    "    \n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Age', fontweight='bold')\n",
    "    plt.xticks([r + bar_width/2 for r in range(len(plot_data))], plot_data['Age'], rotation='vertical')  # Rotate x-axis labels vertically\n",
    "    plt.ylabel(f'{word.capitalize()} Frequency', fontweight='bold')\n",
    "    plt.title(f'Comparison of \"{word.capitalize()}\" Frequency by Age and Gender', fontweight='bold')  # Updated title\n",
    "    \n",
    "    # Creating legend & showing the plot\n",
    "    plt.legend()\n",
    "    plt.tight_layout()  # Adjust layout to not cut off labels\n",
    "\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "            \n",
    "    # Define the output path for saving the graph\n",
    "    output_path = os.path.join(output_directory, f'{word}.jpg')\n",
    "    \n",
    "    # Save the plot to the specified output path\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()  # Close the plot to avoid displaying it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97165e3b",
   "metadata": {},
   "source": [
    "### Age Normalization Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42798fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Age normalization function defined!\n"
     ]
    }
   ],
   "source": [
    "def normalize_age(age):\n",
    "    \"\"\"\n",
    "    Normalize age values by converting to integers and handling edge cases.\n",
    "    \n",
    "    Parameters:\n",
    "    - age: Age value (can be string or numeric)\n",
    "    \n",
    "    Returns:\n",
    "    - int or None: Normalized age or None if invalid\n",
    "    \"\"\"\n",
    "    try:\n",
    "        age_int = int(age)\n",
    "        if age_int < 0 or age_int > 120:  # Reasonable age range\n",
    "            return None\n",
    "        return age_int\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Age normalization function defined!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6757fcc6",
   "metadata": {},
   "source": [
    "### Main Data Processing Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5897b767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Main data processing function defined!\n"
     ]
    }
   ],
   "source": [
    "def process_data(data_path, age_column, text_column, gender_prefix):\n",
    "    \"\"\"\n",
    "    Process gender-specific data including text preprocessing, sentiment analysis, and age normalization.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_path (str): Path to the CSV file containing the data.\n",
    "    - age_column (str): Name of the column containing age information.\n",
    "    - text_column (str): Name of the column containing text data to be processed.\n",
    "    - gender_prefix (str): Prefix to distinguish between male and female data.\n",
    "    \n",
    "    Returns:\n",
    "    - Tuple of processed results: most_common_filtered_words, sentiment_word_freq_by_valid_age\n",
    "    \"\"\"\n",
    "    print(f\"üîÑ Processing {gender_prefix} data...\")\n",
    "    \n",
    "    # Data loading\n",
    "    data_df = pd.read_csv(data_path)\n",
    "    data_df[f'{gender_prefix}_processed_text'] = data_df[text_column].apply(simple_preprocess)\n",
    "    \n",
    "    # Calculate word frequency and identify most common words\n",
    "    all_words = [word for text in data_df[f'{gender_prefix}_processed_text'] for word in text]\n",
    "    english_stopwords = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in all_words if word not in english_stopwords]\n",
    "    filtered_word_freq = Counter(filtered_words)\n",
    "    most_common_filtered_words = filtered_word_freq.most_common(20)\n",
    "    \n",
    "    # Instantiate VADER SentimentIntensityAnalyzer\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    vader_lexicon = sia.lexicon\n",
    "    sentiment_words_from_filtered = [word for word in filtered_words if word in vader_lexicon]\n",
    "    unique_sentiment_words = list(set(sentiment_words_from_filtered))\n",
    "    \n",
    "    # Apply age normalization\n",
    "    data_df[f'normalized_age_{gender_prefix}'] = data_df[age_column].apply(normalize_age)\n",
    "    valid_age_data_df = data_df.dropna(subset=[f'normalized_age_{gender_prefix}'])\n",
    "    grouped_texts = valid_age_data_df.groupby(f'normalized_age_{gender_prefix}')[f'{gender_prefix}_processed_text']\n",
    "    age_grouped_text_valid = grouped_texts.apply(lambda texts: ' '.join(' '.join(text) for text in texts))\n",
    "    \n",
    "    # Word frequency analysis with valid age groups\n",
    "    word_freq_by_valid_age = {}\n",
    "    for age, text in age_grouped_text_valid.items():\n",
    "        words = text.split()\n",
    "        filtered_words = [word for word in words if word not in english_stopwords]\n",
    "        word_freq = Counter(filtered_words)\n",
    "        word_freq_by_valid_age[age] = word_freq\n",
    "    \n",
    "    # Analyzing sentiment word frequency by age\n",
    "    sentiment_word_freq_by_valid_age = pd.DataFrame({\n",
    "        word: [word_freq_by_valid_age[age][word] for age in word_freq_by_valid_age] \n",
    "        for word in unique_sentiment_words\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úÖ {gender_prefix} data processing completed!\")\n",
    "    return most_common_filtered_words, sentiment_word_freq_by_valid_age\n",
    "\n",
    "print(\"‚úÖ Main data processing function defined!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25384a5",
   "metadata": {},
   "source": [
    "### Visualization Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecbafe4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Visualization functions defined!\n"
     ]
    }
   ],
   "source": [
    "def plot_word_frequency(male_freq, female_freq, word, output_dir='../figs/word_frequency_compare'):\n",
    "    \"\"\"\n",
    "    Create and save a bar chart comparing word frequency between male and female data.\n",
    "    \n",
    "    Parameters:\n",
    "    - male_freq (dict): Male word frequency data\n",
    "    - female_freq (dict): Female word frequency data  \n",
    "    - word (str): The word to analyze\n",
    "    - output_dir (str): Directory to save the plot\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Extract data for the specific word\n",
    "    male_data = [male_freq[age].get(word, 0) for age in sorted(male_freq.keys())]\n",
    "    female_data = [female_freq[age].get(word, 0) for age in sorted(female_freq.keys())]\n",
    "    ages = sorted(male_freq.keys())\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(ages))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, male_data, width, label='Male', alpha=0.8)\n",
    "    plt.bar(x + width/2, female_data, width, label='Female', alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('Age Group')\n",
    "    plt.ylabel('Word Frequency')\n",
    "    plt.title(f'Word Frequency Comparison: \"{word}\"')\n",
    "    plt.xticks(x, ages)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(f'{output_dir}/{word}_comparison.jpg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"üìä Chart saved: {word}_comparison.jpg\")\n",
    "\n",
    "print(\"‚úÖ Visualization functions defined!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bdbac8",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis Execution\n",
    "\n",
    "Run the sentiment analysis on both male and female datasets to identify patterns and differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56caf9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöπ Processing male data...\n",
      "üîÑ Processing male data...\n",
      "‚úÖ male data processing completed!\n",
      "üö∫ Processing female data...\n",
      "üîÑ Processing female data...\n",
      "‚úÖ female data processing completed!\n",
      "‚úÖ Sentiment analysis completed for both genders!\n"
     ]
    }
   ],
   "source": [
    "# Process male data\n",
    "print(\"üöπ Processing male data...\")\n",
    "male_common_words, male_sentiment_freq = process_data(\n",
    "    './output/male_data.csv', \n",
    "    'age', \n",
    "    'cleaned_hm', \n",
    "    'male'\n",
    ")\n",
    "\n",
    "# Process female data  \n",
    "print(\"üö∫ Processing female data...\")\n",
    "female_common_words, female_sentiment_freq = process_data(\n",
    "    './output/female_data.csv', \n",
    "    'age', \n",
    "    'cleaned_hm', \n",
    "    'female'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Sentiment analysis completed for both genders!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cde405",
   "metadata": {},
   "source": [
    "## 5. Gender Comparison Analysis\n",
    "\n",
    "Compare sentiment word frequencies between male and female participants across different age groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e65c44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Converting frequencies to percentages...\n",
      "‚úÖ Percentage conversion completed!\n"
     ]
    }
   ],
   "source": [
    "# Convert sentiment frequency data to percentage\n",
    "print(\"üìä Converting frequencies to percentages...\")\n",
    "\n",
    "# Male data processing\n",
    "male_sentiment_percentages = male_sentiment_freq.copy()\n",
    "for col in male_sentiment_percentages.columns:\n",
    "    total = male_sentiment_percentages[col].sum()\n",
    "    if total > 0:\n",
    "        male_sentiment_percentages[col] = (male_sentiment_percentages[col] / total) * 100\n",
    "\n",
    "# Female data processing  \n",
    "female_sentiment_percentages = female_sentiment_freq.copy()\n",
    "for col in female_sentiment_percentages.columns:\n",
    "    total = female_sentiment_percentages[col].sum()\n",
    "    if total > 0:\n",
    "        female_sentiment_percentages[col] = (female_sentiment_percentages[col] / total) * 100\n",
    "\n",
    "print(\"‚úÖ Percentage conversion completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "102b8497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Merging male and female sentiment data...\n",
      "Found 1379 common sentiment words\n",
      "Created comparison dataframe with 79982 rows\n",
      "‚úÖ Data merging completed!\n"
     ]
    }
   ],
   "source": [
    "# Merge male and female data for comparison\n",
    "print(\"üîÑ Merging male and female sentiment data...\")\n",
    "\n",
    "# Get common sentiment words\n",
    "common_sentiment_words = list(set(male_sentiment_percentages.columns) & set(female_sentiment_percentages.columns))\n",
    "print(f\"Found {len(common_sentiment_words)} common sentiment words\")\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_data = []\n",
    "for word in common_sentiment_words:\n",
    "    for age in male_sentiment_percentages.index:\n",
    "        comparison_data.append({\n",
    "            'word': word,\n",
    "            'age': age,\n",
    "            'male_percentage': male_sentiment_percentages.loc[age, word],\n",
    "            'female_percentage': female_sentiment_percentages.loc[age, word]\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(f\"Created comparison dataframe with {len(comparison_df)} rows\")\n",
    "print(\"‚úÖ Data merging completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f4dd4c",
   "metadata": {},
   "source": [
    "## 6. Visualization Generation\n",
    "\n",
    "Generate comparison charts for each sentiment word to visualize gender differences across age groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4449b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Generating comparison charts...\n",
      "‚úÖ Generated 50 comparison charts!\n",
      "üìÅ Charts saved to: ./output/word_frequency_compare/\n"
     ]
    }
   ],
   "source": [
    "# Generate visualization charts\n",
    "print(\"üìä Generating comparison charts...\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('./output/word_frequency_compare', exist_ok=True)\n",
    "\n",
    "# Generate charts for each sentiment word\n",
    "charts_created = 0\n",
    "for word in common_sentiment_words[:50]:  # Limit to first 50 words for demo\n",
    "    try:\n",
    "        # Prepare data for plotting\n",
    "        word_data = comparison_df[comparison_df['word'] == word]\n",
    "        \n",
    "        if len(word_data) > 0:\n",
    "            # Create the plot\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            ages = word_data['age'].values\n",
    "            male_pct = word_data['male_percentage'].values\n",
    "            female_pct = word_data['female_percentage'].values\n",
    "            \n",
    "            x = np.arange(len(ages))\n",
    "            width = 0.35\n",
    "            \n",
    "            plt.bar(x - width/2, male_pct, width, label='Male', alpha=0.8, color='skyblue')\n",
    "            plt.bar(x + width/2, female_pct, width, label='Female', alpha=0.8, color='lightcoral')\n",
    "            \n",
    "            plt.xlabel('Age Group')\n",
    "            plt.ylabel('Percentage (%)')\n",
    "            plt.title(f'Word Frequency Comparison: \"{word}\"')\n",
    "            plt.xticks(x, ages)\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save the plot\n",
    "            plt.savefig(f'./output/word_frequency_compare/{word}_comparison.jpg', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            charts_created += 1\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating chart for '{word}': {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"‚úÖ Generated {charts_created} comparison charts!\")\n",
    "print(\"üìÅ Charts saved to: ./output/word_frequency_compare/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5154320",
   "metadata": {},
   "source": [
    "## 7. Results & Insights\n",
    "\n",
    "Analyze the findings from the sentiment analysis and identify key patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f35d2e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà SENTIMENT ANALYSIS SUMMARY\n",
      "==================================================\n",
      "üìä Dataset Overview:\n",
      "   ‚Ä¢ Total US participants: 79063\n",
      "   ‚Ä¢ Male participants: 44259\n",
      "   ‚Ä¢ Female participants: 34100\n",
      "   ‚Ä¢ Common sentiment words analyzed: 1379\n",
      "\n",
      "üìä Most Common Words (Male):\n",
      "   ‚Ä¢ got: 6137\n",
      "   ‚Ä¢ happy: 5709\n",
      "   ‚Ä¢ made: 4826\n",
      "   ‚Ä¢ work: 4205\n",
      "   ‚Ä¢ new: 4091\n",
      "   ‚Ä¢ went: 3515\n",
      "   ‚Ä¢ time: 3388\n",
      "   ‚Ä¢ able: 2662\n",
      "   ‚Ä¢ good: 2636\n",
      "   ‚Ä¢ day: 2596\n",
      "\n",
      "üìä Most Common Words (Female):\n",
      "   ‚Ä¢ happy: 6381\n",
      "   ‚Ä¢ made: 4568\n",
      "   ‚Ä¢ got: 4563\n",
      "   ‚Ä¢ time: 2899\n",
      "   ‚Ä¢ went: 2870\n",
      "   ‚Ä¢ new: 2695\n",
      "   ‚Ä¢ work: 2670\n",
      "   ‚Ä¢ day: 2543\n",
      "   ‚Ä¢ husband: 2169\n",
      "   ‚Ä¢ able: 2088\n",
      "\n",
      "üìä Analysis Results:\n",
      "   ‚Ä¢ Comparison charts generated: 50\n",
      "   ‚Ä¢ Age groups analyzed: 58\n",
      "   ‚Ä¢ Sentiment words per gender: 1801\n",
      "\n",
      "‚úÖ Sentiment analysis workflow completed successfully!\n",
      "üìÅ Check the '../figs/word_frequency_compare/' directory for visualization charts.\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics\n",
    "print(\"üìà SENTIMENT ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"üìä Dataset Overview:\")\n",
    "print(f\"   ‚Ä¢ Total US participants: {len(us_data)}\")\n",
    "print(f\"   ‚Ä¢ Male participants: {len(male_data)}\")\n",
    "print(f\"   ‚Ä¢ Female participants: {len(female_data)}\")\n",
    "print(f\"   ‚Ä¢ Common sentiment words analyzed: {len(common_sentiment_words)}\")\n",
    "\n",
    "print(f\"\\nüìä Most Common Words (Male):\")\n",
    "for word, count in male_common_words[:10]:\n",
    "    print(f\"   ‚Ä¢ {word}: {count}\")\n",
    "\n",
    "print(f\"\\nüìä Most Common Words (Female):\")\n",
    "for word, count in female_common_words[:10]:\n",
    "    print(f\"   ‚Ä¢ {word}: {count}\")\n",
    "\n",
    "print(f\"\\nüìä Analysis Results:\")\n",
    "print(f\"   ‚Ä¢ Comparison charts generated: {charts_created}\")\n",
    "print(f\"   ‚Ä¢ Age groups analyzed: {len(male_sentiment_percentages.index)}\")\n",
    "print(f\"   ‚Ä¢ Sentiment words per gender: {len(male_sentiment_percentages.columns)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Sentiment analysis workflow completed successfully!\")\n",
    "print(\"üìÅ Check the '../figs/word_frequency_compare/' directory for visualization charts.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
